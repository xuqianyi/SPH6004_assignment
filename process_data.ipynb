{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>aki</th>\n",
       "      <th>gender</th>\n",
       "      <th>admission_age</th>\n",
       "      <th>race</th>\n",
       "      <th>heart_rate_min</th>\n",
       "      <th>heart_rate_max</th>\n",
       "      <th>heart_rate_mean</th>\n",
       "      <th>sbp_min</th>\n",
       "      <th>sbp_max</th>\n",
       "      <th>...</th>\n",
       "      <th>ggt_max</th>\n",
       "      <th>ld_ldh_min</th>\n",
       "      <th>ld_ldh_max</th>\n",
       "      <th>gcs_min</th>\n",
       "      <th>gcs_motor</th>\n",
       "      <th>gcs_verbal</th>\n",
       "      <th>gcs_eyes</th>\n",
       "      <th>gcs_unable</th>\n",
       "      <th>height</th>\n",
       "      <th>weight_admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36570066</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>79.953141</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>100.083333</td>\n",
       "      <td>103.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>236.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39307659</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>78.194169</td>\n",
       "      <td>WHITE - RUSSIAN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>97.263158</td>\n",
       "      <td>97.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38743306</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>65.602396</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>60.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>84.166667</td>\n",
       "      <td>95.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32339865</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>64.906629</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>71.461538</td>\n",
       "      <td>113.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>113.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35526987</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>57.438861</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>57.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.387097</td>\n",
       "      <td>81.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>97.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  aki gender  admission_age                    race  \\\n",
       "0  36570066    3      F      79.953141  BLACK/AFRICAN AMERICAN   \n",
       "1  39307659    0      F      78.194169         WHITE - RUSSIAN   \n",
       "2  38743306    2      F      65.602396                   WHITE   \n",
       "3  32339865    2      F      64.906629                 UNKNOWN   \n",
       "4  35526987    2      M      57.438861                   WHITE   \n",
       "\n",
       "   heart_rate_min  heart_rate_max  heart_rate_mean  sbp_min  sbp_max  ...  \\\n",
       "0            96.0           104.0       100.083333    103.0    126.0  ...   \n",
       "1            72.0           134.0        97.263158     97.0    127.0  ...   \n",
       "2            60.0            97.0        84.166667     95.0    143.0  ...   \n",
       "3            59.0            87.0        71.461538    113.0    150.0  ...   \n",
       "4            57.0           100.0        82.387097     81.0    127.0  ...   \n",
       "\n",
       "   ggt_max  ld_ldh_min  ld_ldh_max  gcs_min  gcs_motor  gcs_verbal  gcs_eyes  \\\n",
       "0      NaN       236.0       318.0     15.0        6.0         5.0       4.0   \n",
       "1      NaN         NaN         NaN     15.0        6.0         5.0       4.0   \n",
       "2      NaN         NaN         NaN     15.0        6.0         5.0       4.0   \n",
       "3      NaN         NaN         NaN     15.0        1.0         0.0       1.0   \n",
       "4      NaN         NaN         NaN     15.0        NaN         0.0       1.0   \n",
       "\n",
       "   gcs_unable  height  weight_admit  \n",
       "0         0.0   157.0         110.0  \n",
       "1         0.0     NaN          82.0  \n",
       "2         0.0     NaN          62.1  \n",
       "3         1.0   170.0         113.1  \n",
       "4         1.0   178.0          97.4  \n",
       "\n",
       "[5 rows x 162 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "data_path = 'sph6004_assignment1_data.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thrombin_max       99.821288\n",
       "thrombin_min       99.821288\n",
       "d_dimer_min        99.785939\n",
       "d_dimer_max        99.785939\n",
       "ggt_max            99.073056\n",
       "                     ...    \n",
       "dbp_min             0.190495\n",
       "dbp_mean            0.190495\n",
       "heart_rate_mean     0.155145\n",
       "heart_rate_max      0.155145\n",
       "heart_rate_min      0.155145\n",
       "Length: 157, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().mean() * 100\n",
    "\n",
    "# Categorical columns for encoding\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Summary of missing values and categorical columns\n",
    "missing_values_summary = missing_values[missing_values > 0].sort_values(ascending=False)\n",
    "\n",
    "\n",
    "missing_values_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = missing_values[missing_values <= 30].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_keep = missing_values[missing_values <= 30].index\n",
    "data_filtered_less_missing_cols = data[columns_to_keep]\n",
    "# Determine if there are rows with a high percentage of missing values in the filtered dataset\n",
    "missing_values_by_row_filtered = data_filtered_less_missing_cols.isnull().sum(axis=1)\n",
    "\n",
    "# Calculate the percentage of missing values for each row in the filtered dataset\n",
    "percentage_missing_by_row_filtered = (missing_values_by_row_filtered / data_filtered_less_missing_cols.shape[1]) * 100\n",
    "\n",
    "# Check the number of rows with more than 50% missing values in the filtered dataset\n",
    "rows_with_high_missing_values_filtered = percentage_missing_by_row_filtered[percentage_missing_by_row_filtered > 50].count()\n",
    "\n",
    "rows_with_high_missing_values_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50763, 65)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with more than 50% missing values in the filtered dataset\n",
    "data_cleaned = data_filtered_less_missing_cols[percentage_missing_by_row_filtered <= 50]\n",
    "\n",
    "# Check the shape of the dataset after removing rows with high missing values\n",
    "data_cleaned_shape = data_cleaned.shape\n",
    "\n",
    "# Verify the cleanup by checking if there are still rows with high missing values\n",
    "missing_values_by_row_cleaned = data_cleaned.isnull().sum(axis=1)\n",
    "percentage_missing_by_row_cleaned = (missing_values_by_row_cleaned / data_cleaned.shape[1]) * 100\n",
    "\n",
    "data_cleaned_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ptt_max              10.222012\n",
       "ptt_min              10.222012\n",
       "inr_max               9.686189\n",
       "inr_min               9.686189\n",
       "pt_max                9.684219\n",
       "pt_min                9.684219\n",
       "calcium_min.1         9.331600\n",
       "calcium_max.1         9.331600\n",
       "temperature_max       3.185391\n",
       "temperature_min       3.185391\n",
       "temperature_mean      3.185391\n",
       "glucose_mean          2.013277\n",
       "glucose_max           2.013277\n",
       "glucose_min           2.013277\n",
       "weight_admit          1.991608\n",
       "glucose_min.2         1.246971\n",
       "glucose_max.2         1.246971\n",
       "gcs_motor             1.245001\n",
       "aniongap_min          0.998759\n",
       "aniongap_max          0.998759\n",
       "gcs_verbal            0.973150\n",
       "potassium_min.1       0.935721\n",
       "potassium_max.1       0.935721\n",
       "bicarbonate_max.1     0.898292\n",
       "bicarbonate_min.1     0.898292\n",
       "sodium_max.1          0.880563\n",
       "sodium_min.1          0.880563\n",
       "chloride_max.1        0.874653\n",
       "chloride_min.1        0.874653\n",
       "gcs_eyes              0.705238\n",
       "hemoglobin_min.1      0.644170\n",
       "hemoglobin_max.1      0.644170\n",
       "wbc_min               0.630380\n",
       "wbc_max               0.630380\n",
       "platelets_max         0.628410\n",
       "platelets_min         0.628410\n",
       "hematocrit_max.1      0.563402\n",
       "hematocrit_min.1      0.563402\n",
       "bun_min               0.504304\n",
       "bun_max               0.504304\n",
       "gcs_unable            0.425507\n",
       "gcs_min               0.425507\n",
       "resp_rate_mean        0.267912\n",
       "resp_rate_max         0.267912\n",
       "resp_rate_min         0.267912\n",
       "spo2_min              0.226543\n",
       "spo2_max              0.226543\n",
       "spo2_mean             0.226543\n",
       "mbp_mean              0.214723\n",
       "mbp_max               0.214723\n",
       "mbp_min               0.214723\n",
       "dbp_mean              0.181234\n",
       "dbp_max               0.181234\n",
       "dbp_min               0.181234\n",
       "sbp_mean              0.181234\n",
       "sbp_max               0.181234\n",
       "sbp_min               0.181234\n",
       "heart_rate_max        0.151685\n",
       "heart_rate_mean       0.151685\n",
       "heart_rate_min        0.151685\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values_cleaned = data_cleaned.isnull().mean() * 100\n",
    "\n",
    "# Summary of missing values and categorical columns\n",
    "missing_values_cleaned_summary = missing_values_cleaned[missing_values_cleaned > 0].sort_values(ascending=False)\n",
    "\n",
    "\n",
    "missing_values_cleaned_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data_cleaned.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.to_csv('data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, encode categorical variables manually (gender and race for now)\n",
    "data_cleaned['gender'] = data_cleaned['gender'].map({'F': 0, 'M': 1})\n",
    "data_cleaned = data_cleaned.drop(columns=['race', 'id'])\n",
    "# Define the target variable (y) and the features (X)\n",
    "X = data_cleaned.drop('aki', axis=1)\n",
    "y = data_cleaned['aki']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Absolute Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bun_max</td>\n",
       "      <td>0.242342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bun_min</td>\n",
       "      <td>0.234780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gcs_verbal</td>\n",
       "      <td>0.195807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dbp_min</td>\n",
       "      <td>0.181049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sbp_min</td>\n",
       "      <td>0.178101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>chloride_min.1</td>\n",
       "      <td>0.006101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>dbp_max</td>\n",
       "      <td>0.004455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>glucose_min</td>\n",
       "      <td>0.001412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>bicarbonate_max.1</td>\n",
       "      <td>0.000549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature  Absolute Correlation\n",
       "0             bun_max              0.242342\n",
       "1             bun_min              0.234780\n",
       "2          gcs_verbal              0.195807\n",
       "3             dbp_min              0.181049\n",
       "4             sbp_min              0.178101\n",
       "..                ...                   ...\n",
       "57     chloride_min.1              0.006101\n",
       "58            dbp_max              0.004455\n",
       "59        glucose_min              0.001412\n",
       "60  bicarbonate_max.1              0.000549\n",
       "61             gender                   NaN\n",
       "\n",
       "[62 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compute the correlation of each feature with the target variable\n",
    "correlations = X.corrwith(y)\n",
    "\n",
    "# Convert to a DataFrame, take the absolute values, and sort by correlation strength\n",
    "correlations_df = correlations.abs().sort_values(ascending=False).reset_index()\n",
    "correlations_df.columns = ['Feature', 'Absolute Correlation']\n",
    "\n",
    "# Display the ranked features based on their absolute correlation with 'aki'\n",
    "correlations_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_features = correlations_df[correlations_df['Absolute Correlation']>0.15]['Feature']\n",
    "X_selected = data_cleaned[candidate_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bun_max', 'bun_min', 'gcs_verbal', 'dbp_min', 'sbp_min', 'mbp_min',\n",
       "       'admission_age', 'potassium_max.1', 'aniongap_max', 'ptt_max',\n",
       "       'gcs_unable', 'pt_max', 'gcs_eyes', 'inr_max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:0.40520043336944744 candidate:bun_max\n",
      "score:0.40066975278242883 candidate:bun_min\n",
      "score:0.3914114054959125 candidate:gcs_verbal\n",
      "score:0.37594799566630555 candidate:dbp_min\n",
      "score:0.3776223776223776 candidate:sbp_min\n",
      "score:0.3725992317541613 candidate:mbp_min\n",
      "score:0.28543287698217273 candidate:admission_age\n",
      "score:0.3706293706293706 candidate:potassium_max.1\n",
      "score:0.35437801634984734 candidate:aniongap_max\n",
      "score:0.35152171771890084 candidate:ptt_max\n",
      "score:0.3702353984044125 candidate:gcs_unable\n",
      "score:0.3792967595784497 candidate:pt_max\n",
      "score:0.37466758593519156 candidate:gcs_eyes\n",
      "score:0.38422141239042645 candidate:inr_max\n",
      "score:0.3935782527331823 candidate:bun_min\n",
      "score:0.4076627597754358 candidate:gcs_verbal\n",
      "score:0.3781148429035753 candidate:dbp_min\n",
      "score:0.3697429331232148 candidate:sbp_min\n",
      "score:0.37486457204767065 candidate:mbp_min\n",
      "score:0.31123805771693097 candidate:admission_age\n",
      "score:0.37555402344134736 candidate:potassium_max.1\n",
      "score:0.38589579434649857 candidate:aniongap_max\n",
      "score:0.34738500935684036 candidate:ptt_max\n",
      "score:0.41101152368758004 candidate:gcs_unable\n",
      "score:0.36560622476115434 candidate:pt_max\n",
      "score:0.40914015561902883 candidate:gcs_eyes\n",
      "score:0.39978331527627303 candidate:inr_max\n",
      "score:0.4020486555697823 candidate:bun_min\n",
      "score:0.4081552250566335 candidate:gcs_verbal\n",
      "score:0.37791785679109624 candidate:dbp_min\n",
      "score:0.3641288289175613 candidate:sbp_min\n",
      "score:0.37919826652221017 candidate:mbp_min\n",
      "score:0.32020092583472864 candidate:admission_age\n",
      "score:0.3829410026593125 candidate:potassium_max.1\n",
      "score:0.38638825962769624 candidate:aniongap_max\n",
      "score:0.353393085787452 candidate:ptt_max\n",
      "score:0.3689549886732985 candidate:pt_max\n",
      "score:0.41012508618142424 candidate:gcs_eyes\n",
      "score:0.3993893430513149 candidate:inr_max\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bun_max', 'gcs_unable']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing a basic version of Forward Selection\n",
    "# Start with no variables and add them one by one\n",
    "selected_features = []\n",
    "current_score, best_new_score = 0.0, 0.0\n",
    "\n",
    "while True:\n",
    "    scores_with_candidates = []\n",
    "    for feature in X_train.columns:\n",
    "        if feature not in selected_features:\n",
    "            X_train_selected = X_train[selected_features + [feature]]\n",
    "            X_test_selected = X_test[selected_features + [feature]]\n",
    "            rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            rf_classifier.fit(X_train_selected, y_train)\n",
    "            y_pred = rf_classifier.predict(X_test_selected)\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "            scores_with_candidates.append((score, feature))\n",
    "            print(f'score:{score} candidate:{feature}')\n",
    "    \n",
    "    scores_with_candidates.sort(reverse=True)\n",
    "    best_new_score, best_candidate = scores_with_candidates[0]\n",
    "    \n",
    "    if best_new_score > current_score:\n",
    "        selected_features.append(best_candidate)\n",
    "        current_score = best_new_score\n",
    "    else:\n",
    "        break  # Exit loop if no improvement\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.41012508618142424, 'gcs_eyes'),\n",
       " (0.4081552250566335, 'gcs_verbal'),\n",
       " (0.4020486555697823, 'bun_min'),\n",
       " (0.3993893430513149, 'inr_max'),\n",
       " (0.38638825962769624, 'aniongap_max'),\n",
       " (0.3829410026593125, 'potassium_max.1'),\n",
       " (0.37919826652221017, 'mbp_min'),\n",
       " (0.37791785679109624, 'dbp_min'),\n",
       " (0.3689549886732985, 'pt_max'),\n",
       " (0.3641288289175613, 'sbp_min'),\n",
       " (0.353393085787452, 'ptt_max'),\n",
       " (0.32020092583472864, 'admission_age')]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_with_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected_final = data_cleaned[selected_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.61      0.52      3319\n",
      "           1       0.16      0.00      0.01      1989\n",
      "           2       0.38      0.51      0.44      3309\n",
      "           3       0.37      0.30      0.33      1536\n",
      "\n",
      "    accuracy                           0.41     10153\n",
      "   macro avg       0.34      0.36      0.32     10153\n",
      "weighted avg       0.36      0.41      0.36     10153\n",
      "\n",
      "Accuracy: 0.41101152368758004\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.38303949571555207\n"
     ]
    }
   ],
   "source": [
    "# Initializing the SVM classifier\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Fitting the SVM classifier to the Training set\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluating the SVM classifier\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianyi/anaconda3/envs/hmarl/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.41642864178075445\n"
     ]
    }
   ],
   "source": [
    "# Initializing the AdaBoost classifier with a Decision Tree base estimator\n",
    "ada_classifier = AdaBoostClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fitting the AdaBoost classifier to the Training set\n",
    "ada_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_ada = ada_classifier.predict(X_test)\n",
    "\n",
    "# Evaluating the AdaBoost classifier\n",
    "print(\"AdaBoost Accuracy:\", accuracy_score(y_test, y_pred_ada))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.41770905151186843\n"
     ]
    }
   ],
   "source": [
    "# Initializing the Gradient Boosting classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Fitting the Gradient Boosting classifier to the Training set\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_gb = gb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluating the Gradient Boosting classifier\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmarl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
